{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWeWolUUfrxb"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "!pip install -q swig\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"BipedalWalker-v3\", render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "plt.imshow(env.render())\n",
        "plt.axis(\"off\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "YCMGsA06fxbu",
        "outputId": "0eba606a-fae1-4e7e-a7ec-01f85ab6e40b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Module, Linear, ReLU, Tanh, Sequential\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class Policy(Module):\n",
        "\n",
        "  def __init__(self, hidden_size, obs_size, out_dims):\n",
        "    super().__init__()\n",
        "    self.net = Sequential(\n",
        "        Linear(obs_size, hidden_size),\n",
        "        ReLU(),\n",
        "        Linear(hidden_size, hidden_size),\n",
        "        ReLU(),\n",
        "        Linear(hidden_size, out_dims))\n",
        "\n",
        "  def mu(self, state):\n",
        "    return self.net(state)\n",
        "\n",
        "  def forward(self, state, epsilon=0.0):\n",
        "    mu = self.mu(state)\n",
        "    mu = mu + torch.normal(0, epsilon, mu.size(), device=mu.device)\n",
        "    action = torch.tanh(mu)\n",
        "    return action.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "kstZoOyPgD9S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QNet(Module):\n",
        "\n",
        "  def __init__(self, hidden_size, obs_size, out_dims):\n",
        "    super().__init__()\n",
        "    self.net = Sequential(\n",
        "          Linear(obs_size + out_dims, hidden_size),\n",
        "          ReLU(),\n",
        "          Linear(hidden_size, hidden_size),\n",
        "          ReLU(),\n",
        "          Linear(hidden_size, 1))\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    state_action = torch.hstack((state, action))\n",
        "    return self.net(state_action)"
      ],
      "metadata": {
        "id": "iettfMJzhohW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random\n",
        "\n",
        "class ReplayBuffer:\n",
        "\n",
        "  def __init__(self, capacity):\n",
        "    self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def append(self, experience):\n",
        "    self.buffer.append(experience)\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    return random.sample(self.buffer, batch_size)\n",
        ""
      ],
      "metadata": {
        "id": "bMww-ySEiDYo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polyak_average(net, target_net, tau=0.01):\n",
        "  for qp, tp in zip(net.parameters(), target_net.parameters()):\n",
        "    tp.data.copy_(tau * qp.data + (1 - tau) * tp.data)"
      ],
      "metadata": {
        "id": "TPqOGMGEiI4J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "def create_gym_environment(name):\n",
        "  environment = gym.make(name, render_mode=\"rgb_array\")\n",
        "  environment = RecordVideo(environment, video_folder=f\"./{name}_recored_episodes\", episode_trigger=lambda x: x % 25 == 0, disable_logger=True)\n",
        "\n",
        "  return environment"
      ],
      "metadata": {
        "id": "BkmqWx5gkGy-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn.functional import smooth_l1_loss\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "\n",
        "class DeepDeterministicPolicyGradient():\n",
        "  def __init__(self, env_name, nets=None, capacity=100_000,\n",
        "               batch_size=256, lr=1e-3, hidden_size=128, gamma=0.99, tau=0.05,\n",
        "               loss_fn=smooth_l1_loss, optim=AdamW, eps_start=1.0, eps_end=0.15,\n",
        "               eps_last_episode=600, samples_per_epoch=1024, repeat_action_rate=5):\n",
        "    self.env = create_gym_environment(env_name)\n",
        "    self.obs = self.env.reset()\n",
        "\n",
        "    obs_size = self.env.observation_space.shape[0]\n",
        "    n_actions = self.env.action_space.shape[0]\n",
        "\n",
        "    self.q_net = QNet(hidden_size, obs_size, n_actions).to(device) if not nets else nets[\"q_net\"].to(device)\n",
        "    self.policy = Policy(hidden_size, obs_size, n_actions).to(device) if not nets else nets[\"policy\"].to(device)\n",
        "    self.q_net_optimizer = optim(self.q_net.parameters(), lr=lr)\n",
        "    self.policy_optimizer = optim(self.policy.parameters(), lr=lr)\n",
        "\n",
        "    self.target_q_net = deepcopy(self.q_net)\n",
        "    self.target_policy = deepcopy(self.policy)\n",
        "\n",
        "    self.buffer = ReplayBuffer(capacity=capacity)\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "    self.gamma = gamma\n",
        "    self.tau = tau\n",
        "    self.batch_size = batch_size\n",
        "    self.eps_start = eps_start\n",
        "    self.eps_end = eps_end\n",
        "    self.eps_last_episode = eps_last_episode\n",
        "    self.samples_per_epoch = samples_per_epoch\n",
        "    self.lr = lr\n",
        "\n",
        "    self.current_epoch = 1\n",
        "    self.log = []\n",
        "    self.returns = []\n",
        "    self.episode_lengths = []\n",
        "    self.repeat_action_rate = repeat_action_rate\n",
        "\n",
        "    while len(self.buffer) < self.samples_per_epoch:\n",
        "      self.play_episode()\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def play_episode(self, policy=None, epsilon=0.0):\n",
        "      state = self.env.reset()[0]\n",
        "      state = torch.tensor(state, device=device)\n",
        "      done = False\n",
        "      rewards = 0\n",
        "      epsiode_length = 0\n",
        "\n",
        "      while not done:\n",
        "        if policy:\n",
        "          action = self.policy(state.unsqueeze(0), epsilon=epsilon).squeeze()\n",
        "        else:\n",
        "          action = self.env.action_space.sample()\n",
        "\n",
        "        for _ in range(self.repeat_action_rate):\n",
        "          next_state, reward, done1, done2, info = self.env.step(action)\n",
        "          rewards += reward\n",
        "          epsiode_length += 1\n",
        "        done = done1 or done2\n",
        "\n",
        "        next_state, action, reward, done = list(map(lambda x: torch.tensor(x, device=device), [next_state, action, reward, done]))\n",
        "        exp = (state, action, reward, done, next_state)\n",
        "        self.buffer.append(exp)\n",
        "\n",
        "        state = next_state\n",
        "      return rewards, epsiode_length\n",
        "\n",
        "  def training_step(self):\n",
        "      batch_T = self.buffer.sample(self.batch_size)\n",
        "      batch = list(map(torch.stack, zip(*batch_T)))\n",
        "\n",
        "      states, actions, rewards, dones, next_states = batch\n",
        "      rewards = rewards.unsqueeze(1)\n",
        "      dones = dones.unsqueeze(1)\n",
        "\n",
        "      action_values = self.q_net(states, actions)\n",
        "      next_actions = self.target_policy.mu(next_states)\n",
        "      next_action_values = self.target_q_net(next_states, next_actions)\n",
        "      next_action_values[dones] = 0.0\n",
        "\n",
        "      expected_action_values = rewards + self.gamma * next_action_values\n",
        "      q_loss = self.loss_fn(action_values, expected_action_values)\n",
        "\n",
        "      self.q_net_optimizer.zero_grad()\n",
        "      q_loss.backward()\n",
        "      self.q_net_optimizer.step()\n",
        "\n",
        "      mu = self.policy.mu(states)\n",
        "      policy_loss = - self.q_net(states, mu).mean()\n",
        "\n",
        "      self.policy_optimizer.zero_grad()\n",
        "      policy_loss.backward()\n",
        "      self.policy_optimizer.step()\n",
        "\n",
        "      return q_loss, policy_loss\n",
        "\n",
        "  def training_epoch_end(self):\n",
        "      epsilon = max(self.eps_end, self.eps_start - self.current_epoch / self.eps_last_episode)\n",
        "      last_return, episode_length = self.play_episode(self.policy, epsilon=epsilon)\n",
        "\n",
        "      polyak_average(self.q_net, self.target_q_net, tau=self.tau)\n",
        "      polyak_average(self.policy, self.target_policy, tau=self.tau)\n",
        "      self.current_epoch += 1\n",
        "\n",
        "      return last_return, episode_length\n",
        "\n",
        "  def fit(self, n_epoch):\n",
        "      for epoch in range(n_epoch):\n",
        "        loss_total = 0\n",
        "        for _ in range(self.samples_per_epoch//self.batch_size):\n",
        "          loss = self.training_step()\n",
        "\n",
        "        last_return, episode_length  = self.training_epoch_end()\n",
        "\n",
        "        self.returns.append(last_return)\n",
        "        self.episode_lengths.append(episode_length)\n",
        "        self.log.append([self.current_epoch, last_return])\n",
        "\n",
        "        if self.current_epoch % 25 == 0:\n",
        "          print(f\"Epoch: {self.current_epoch}, mean return: {np.mean(self.returns[-10:]):.2f}, \" \\\n",
        "            f\"mean episode length: {np.mean(self.episode_lengths[-10:])}\")"
      ],
      "metadata": {
        "id": "F2FdygjFiUfw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alg = DeepDeterministicPolicyGradient(\"BipedalWalker-v3\", repeat_action_rate=3, lr=1e-4, eps_start=0.3, eps_end=0.15)\n",
        "alg.fit(1500)"
      ],
      "metadata": {
        "id": "-eFfzSM6smCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
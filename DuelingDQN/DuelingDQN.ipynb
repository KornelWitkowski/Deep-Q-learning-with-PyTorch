{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dueling DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewjPXkBCnCMQ",
    "outputId": "0c8b0f71-50c6-4e57-b803-f33df2ad7859",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gymnasium\n",
    "!pip install -q swig\n",
    "!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "GmaSyp8IFl5l",
    "outputId": "b9da8222-741c-4214-d872-410071ecc7fe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"rgb_array\", continuous=False)\n",
    "env.reset()\n",
    "for i in range(50):\n",
    "  env.step(3)\n",
    "\n",
    "plt.imshow(env.render())\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kSmaEpjwGJpo"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def epsilon_greedy(state, env, net, epsilon=0.0):\n",
    "  if np.random.random() < epsilon:\n",
    "    action = env.action_space.sample()\n",
    "  else:\n",
    "    q_values = net(state)\n",
    "    _, action = torch.max(q_values, dim=1)\n",
    "    action = int(action.item())\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zrHaVDV0GojV"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "\n",
    "  def __init__(self, capacity):\n",
    "    self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.buffer)\n",
    "\n",
    "  def append(self, experience):\n",
    "    self.buffer.append(experience)\n",
    "\n",
    "  def sample(self, batch_size):\n",
    "    return random.sample(self.buffer, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JmjZ7tvfGpBA"
   },
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "def create_gym_environment(name):\n",
    "  environment = gym.make(name, render_mode=\"rgb_array\", continuous=False)\n",
    "  environment = RecordVideo(environment, video_folder=f\"./{name}_recored_episodes\", episode_trigger=lambda x: x % 5 == 0)\n",
    "\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3f6ogBLZuzWg"
   },
   "outputs": [],
   "source": [
    "from torch.nn import ReLU, Conv2d, ReLU, Module, Flatten, AvgPool2d, Sequential, Linear\n",
    "import torch.autograd as autograd\n",
    "\n",
    "class ConvDuelingDQN(Module):\n",
    "\n",
    "    def __init__(self, hidden_size, input_dim, output_dim):\n",
    "        super(ConvDuelingDQN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        self.conv = Sequential(\n",
    "            Conv2d(3, 16, kernel_size=3, stride=3),\n",
    "            ReLU(),\n",
    "            Conv2d(16, 32, kernel_size=3, stride=3),\n",
    "            ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.fc_input_dim = 3200\n",
    "\n",
    "        self.value_stream = Sequential(\n",
    "            Linear(self.fc_input_dim, hidden_size),\n",
    "            ReLU(),\n",
    "            Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "        self.advantage_stream = Sequential(\n",
    "            Linear(self.fc_input_dim, hidden_size),\n",
    "            ReLU(),\n",
    "            Linear(hidden_size, self.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        features = self.conv(state)\n",
    "        values = self.value_stream(features)\n",
    "        advantages = self.advantage_stream(features)\n",
    "        qvals = values + (advantages - advantages.mean())\n",
    "        return qvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "e9-QREClGuxG"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.optim import AdamW\n",
    "from copy import deepcopy\n",
    "from torch.nn.functional import smooth_l1_loss\n",
    "\n",
    "class DeepQLearning():\n",
    "\n",
    "  def __init__(self, env_name, net=None, policy=epsilon_greedy, capacity=20_000,\n",
    "               batch_size=256, lr=1e-3, hidden_size=128, gamma=0.99,\n",
    "               loss_fn=smooth_l1_loss, optim=AdamW, eps_start=1.0, eps_end=0.15,\n",
    "               eps_last_episode=600, samples_per_epoch=1024, sync_rate=25, play_episode_rate=5):\n",
    "      self.env_name = env_name\n",
    "      self.env = create_gym_environment(env_name)\n",
    "\n",
    "      obs_size = self.env.observation_space.shape[0]\n",
    "      n_actions = self.env.action_space.n\n",
    "\n",
    "      self.q_net = net if net else ConvDuelingDQN(hidden_size, obs_size, n_actions)\n",
    "\n",
    "      self.optim = optim(self.q_net.parameters(), lr)\n",
    "      self.target_q_net = deepcopy(self.q_net)\n",
    "\n",
    "      self.policy = policy\n",
    "      self.buffer = ReplayBuffer(capacity=capacity)\n",
    "      self.loss_fn = loss_fn\n",
    "\n",
    "      self.gamma = gamma\n",
    "      self.batch_size = batch_size\n",
    "      self.eps_start = eps_start\n",
    "      self.eps_end = eps_end\n",
    "      self.eps_last_episode = eps_last_episode\n",
    "      self.sync_rate = sync_rate\n",
    "      self.samples_per_epoch = samples_per_epoch\n",
    "      self.lr = lr\n",
    "      self.play_episode_rate = play_episode_rate\n",
    "\n",
    "      self.current_epoch = 1\n",
    "      self.log = []\n",
    "      self.returns = []\n",
    "      self.episode_lengths = []\n",
    "      self.start_time = time.time()\n",
    "\n",
    "      while len(self.buffer) < self.samples_per_epoch:\n",
    "        self.play_episode(epsilon=1.0)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def play_episode(self, policy=None, epsilon=0.):\n",
    "      state = self.env.reset()[0]\n",
    "      done = False\n",
    "      rewards = 0\n",
    "      epsiode_length = 0\n",
    "\n",
    "      while not done:\n",
    "        state_v = torch.permute(torch.tensor(state), (2, 0, 1))/255.0\n",
    "        if policy:\n",
    "          action = policy(state_v.unsqueeze(0), self.env, self.q_net, epsilon=epsilon)\n",
    "        else:\n",
    "          action = self.env.action_space.sample()\n",
    "\n",
    "\n",
    "        next_state, reward, done1, done2, info = self.env.step(action)\n",
    "        done = done1 or done2\n",
    "\n",
    "        rewards += reward\n",
    "        epsiode_length += 1\n",
    "\n",
    "        next_state_v = torch.permute(torch.tensor(next_state), (2, 0, 1))/255.0\n",
    "        action_v = torch.tensor(action)\n",
    "        reward_v = torch.tensor(reward)\n",
    "        done_v = torch.tensor(done)\n",
    "        exp = (state_v, action_v, reward_v, done_v, next_state_v)\n",
    "\n",
    "        self.buffer.append(exp)\n",
    "        state = next_state\n",
    "      return rewards, epsiode_length\n",
    "\n",
    "\n",
    "  def fit(self, n_epoch):\n",
    "      for epoch in range(n_epoch):\n",
    "        loss_total = 0\n",
    "        for _ in range(self.samples_per_epoch//self.batch_size):\n",
    "\n",
    "          loss = self.training_step()\n",
    "          loss_total += loss\n",
    "\n",
    "        last_return, episode_length  = self.training_epoch_end()\n",
    "\n",
    "        if last_return is not None:\n",
    "          self.returns.append(last_return)\n",
    "          self.episode_lengths.append(episode_length)\n",
    "          self.log.append([self.current_epoch, last_return, loss_total.item()])\n",
    "\n",
    "        if self.current_epoch % 25 == 0:\n",
    "          print(f\"Epoch: {self.current_epoch}, mean return: {np.mean(self.returns[-10:]):.2f}, \" \\\n",
    "           f\"mean episode length: {np.mean(self.episode_lengths[-10:])}, loss: {loss_total:.2f}\")\n",
    "\n",
    "\n",
    "  def training_step(self):\n",
    "      batch_T = self.buffer.sample(self.batch_size)\n",
    "      batch = list(map(torch.stack, zip(*batch_T)))\n",
    "\n",
    "      states, actions, rewards, dones, next_states = batch\n",
    "      actions = actions.unsqueeze(1)\n",
    "      rewards = rewards.unsqueeze(1)\n",
    "      dones = dones.unsqueeze(1)\n",
    "      state_action_values = self.q_net(states).gather(1, actions)\n",
    "\n",
    "      next_action_values, _ = self.target_q_net(next_states).max(dim=1, keepdim=True)\n",
    "      next_action_values[dones] = 0.0\n",
    "\n",
    "      expected_state_action_values = rewards + self.gamma * next_action_values\n",
    "      loss = self.loss_fn(state_action_values, expected_state_action_values)\n",
    "\n",
    "      self.optim.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optim.step()\n",
    "      return loss\n",
    "\n",
    "\n",
    "  def training_epoch_end(self):\n",
    "      epsilon = max(self.eps_end, self.eps_start - self.current_epoch / self.eps_last_episode)\n",
    "\n",
    "      if self.current_epoch % self.play_episode_rate == 0:\n",
    "        last_return, episode_length = self.play_episode(policy=self.policy, epsilon=epsilon)\n",
    "      else:\n",
    "        last_return = None\n",
    "        episode_length = None\n",
    "\n",
    "      if self.current_epoch % self.sync_rate == 0:\n",
    "        self.target_q_net.load_state_dict(self.q_net.state_dict())\n",
    "      self.current_epoch += 1\n",
    "      return last_return, episode_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "-umP_Wy5vVdZ"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(\"CarRacing-v2_recored_episodes\", ignore_errors=True)\n",
    "except:\n",
    "    pass\n",
    "# q_net = torch.load(\"CarRacing_qnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qv6Ay46BMjN0",
    "outputId": "0b78bd01-bf09-46d0-e40c-a0dc165b9986",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algo = DeepQLearning(\"CarRacing-v2\", q_net, eps_last_episode=1200, eps_start=0.8, eps_end=0.10, samples_per_epoch=512, batch_size=128)\n",
    "algo.fit(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdnwbgAXM4oZ",
    "outputId": "ebd447f9-e8f0-4571-8279-683b2ced663f"
   },
   "outputs": [],
   "source": [
    "torch.save(algo.q_net, \"CarRacing_qnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nzSR4803xmVo"
   },
   "outputs": [],
   "source": [
    "q_net = torch.load(\"CarRacing_qnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "def create_test_gym_environment(name):\n",
    "  environment = gym.make(name, render_mode=\"rgb_array\", continuous=False)\n",
    "  environment = RecordVideo(environment, video_folder=f\"./test_{name}\", episode_trigger=lambda x: x % 1 == 0)\n",
    "\n",
    "  return environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def play_episode(test_env, q_net):\n",
    "      state = test_env.reset()[0]\n",
    "      done = False\n",
    "\n",
    "      while not done:\n",
    "        state_v = torch.permute(torch.tensor(state), (2, 0, 1))/255.0\n",
    "        action = epsilon_greedy(state_v.unsqueeze(0), test_env, q_net, epsilon=0.0)\n",
    "\n",
    "        next_state, reward, done1, done2, info = test_env.step(action)\n",
    "        done = done1 or done2\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = create_test_gym_environment(\"CarRacing-v2\")\n",
    "for i in range(10):\n",
    "    play_episode(test_env, q_net)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
